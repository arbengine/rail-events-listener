import 'dotenv/config'; // Ensure env vars are loaded first //
import { collectDefaultMetrics, Counter } from 'prom-client';
import { getTemporalClient, closeTemporalClient } from './temporalClient.js';
import { WorkflowIdReusePolicy } from '@temporalio/common';
import { pool, query, closePool, STATEMENT_TIMEOUT_MS, IDLE_TX_TIMEOUT_MS, } from './pg.js';
// â”€â”€ NATS setup (new) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import { connect as natsConnect, StringCodec, } from 'nats';
let natsConn = null;
const sc = StringCodec();
async function getNats() {
    if (!natsConn) {
        natsConn = await natsConnect({
            servers: process.env.NATS_URL || 'nats://nats-scalable:4222',
        });
        console.log('rail-events-listener â†’ connected to NATS');
    }
    return natsConn;
}
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import { toDelta } from './utils/delta.js';
import { initializeWebSocketServer, broadcast, closeWebSocketServer } from './websocketServer.js';
// ----------------------------------------------------------------------------
// Lightweight console-based logger (swap for pino in prod if desired)
export const logger = {
    info: (...a) => console.log(...a),
    warn: (...a) => console.warn(...a),
    error: (...a) => console.error(...a),
    debug: (...a) => console.debug(...a),
    trace: (...a) => console.trace(...a),
    fatal: (...a) => console.error(...a),
};
// -----------------------------------------------------------------------------
collectDefaultMetrics({ prefix: 'rail_events_listener_' });
const lastEventByNode = new Map(); // key = taskId:nodeId
const CHANNEL = process.env.PG_CHANNEL || 'rail_event';
const USE_DAG_RUNNER = process.env.DAG_RUNNER === 'true';
const INSTANCE_ID = process.env.HOSTNAME || 'unknown';
const listenerErrors = new Counter({
    name: 'busywork_listener_errors_total',
    help: 'Unhandled errors in rail-events-listener',
    labelNames: ['instance_id'],
});
const notificationsProcessed = new Counter({
    name: 'rail_events_listener_notifications_processed_total',
    help: 'Total notifications processed',
    labelNames: ['status', 'instance_id'],
});
const logCtx = (extra = {}) => ({ instance_id: INSTANCE_ID, ...extra });
let temporalClient;
let activeListenerClient; // track for graceful shutdown
// -----------------------------------------------------------------------------
/** Boot a dedicated, long-lived LISTEN socket (retries inside p-retry). */
export async function bootListener() {
    logger.info('Attempting to connect to PostgreSQL for LISTENâ€¦');
    if (activeListenerClient) {
        try {
            activeListenerClient.release();
        }
        catch { }
        activeListenerClient = undefined;
    }
    const client = await pool.connect();
    activeListenerClient = client;
    logger.info(logCtx({
        statement_timeout: STATEMENT_TIMEOUT_MS,
        idle_tx_timeout: IDLE_TX_TIMEOUT_MS,
    }), 'âœ… Connected to PG for LISTEN');
    await client.query(`SET statement_timeout TO 0; SET idle_in_transaction_session_timeout TO 0; SET client_min_messages TO WARNING;`);
    logger.debug('Session timeouts set to 0 for LISTEN socket');
    client.on('error', (err) => {
        listenerErrors.inc({ instance_id: INSTANCE_ID });
        logger.error(logCtx({ err }), 'ðŸ’¥ PostgreSQL LISTEN client error â€” reconnecting');
        try {
            client.release(err);
        }
        catch { }
        activeListenerClient = undefined;
    });
    client.on('notification', (msg) => handleNotification(msg).catch((err) => {
        logger.error(logCtx({ err, payload: msg.payload }), 'ðŸ’¥ Error in handleNotification');
        listenerErrors.inc({ instance_id: INSTANCE_ID });
    }));
    await client.query(`LISTEN ${CHANNEL}`);
    logger.info(logCtx({ channel: CHANNEL }), 'ðŸ”” LISTENING for events');
    /* ---------- 30-second SQL heartbeat ---------- */
    const heartbeat = setInterval(async () => {
        try {
            await query('SELECT 1'); // âœ… grabs a fresh pool connection
            logger.info(logCtx(), 'â¤ï¸ listener heartbeat OK');
        }
        catch (err) {
            logger.warn(logCtx({ err }), 'ðŸ’” heartbeat failed â€“ connection likely lost');
        }
    }, 30_000);
    /* clear the interval when this client ends */
    client.once('end', () => clearInterval(heartbeat));
}
// -----------------------------------------------------------------------------
/** Parse and forward one NOTIFY payload. */
async function handleNotification(msg) {
    if (msg.channel !== CHANNEL || !msg.payload)
        return;
    /* â”€â”€ parse JSON then map camelâ†’snake BEFORE validating â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
    let raw;
    try {
        raw = JSON.parse(msg.payload);
    }
    catch (err) {
        logger.error(logCtx({ err, payload: msg.payload }), 'Failed JSON.parse');
        return;
    }
    /* basic shape-check */
    if (typeof raw !== 'object' || !raw.task_id || !raw.node_id || !raw.state) {
        logger.warn(logCtx({ payload: msg.payload }), 'Received payload does not conform to RailEvent structure');
        return;
    }
    const curr = raw;
    const key = `${curr.task_id}:${curr.node_id}`;
    const prev = lastEventByNode.get(key) ?? null;
    let snapshotVersion = -1; // Default/error value
    try {
        const { rows } = await query('SELECT txid_current() AS v');
        if (rows && rows.length > 0 && rows[0].v !== null && rows[0].v !== undefined) {
            const parsedVersion = Number(rows[0].v);
            if (!isNaN(parsedVersion)) {
                snapshotVersion = parsedVersion;
                logger.info(logCtx({ taskId: curr.task_id, nodeId: curr.node_id, snapshotVersion }), 'Retrieved snapshotVersion for delta');
            }
            else {
                logger.warn(logCtx({ taskId: curr.task_id, nodeId: curr.node_id, rawValue: rows[0].v }), 'Failed to convert txid_current to Number for snapshotVersion');
            }
        }
        else {
            logger.warn(logCtx({ taskId: curr.task_id, nodeId: curr.node_id, rows }), 'Failed to retrieve txid_current or rows were empty/undefined for snapshotVersion');
        }
    }
    catch (err) {
        logger.error(logCtx({ err: { message: err.message, stack: err.stack }, taskId: curr.task_id, nodeId: curr.node_id }), 'ðŸ’¥ Error fetching txid_current for snapshot version');
        // snapshotVersion remains -1, indicating an issue. The frontend should handle this gracefully.
    }
    const delta = toDelta(curr, prev, snapshotVersion);
    broadcast(delta); // Call the imported broadcast function
    /* â”€â”€ NEW: publish â€œnode doneâ€ over NATS for side-cars â”€â”€ */
    if (curr.state === 'DONE') {
        try {
            const nc = await getNats();
            await nc.publish(`busywork.node.done.${curr.node_id}`, // subject
            sc.encode(JSON.stringify({
                taskId: curr.task_id,
                nodeId: curr.node_id,
            })));
            logger.debug(logCtx({ node: curr.node_id }), 'ðŸ“¤ NATS busywork.node.done published');
        }
        catch (err) {
            logger.error(logCtx({ err }), 'ðŸ’¥ NATS publish failed (non-fatal)');
        }
    }
    logger.info({ deltaPayload: true, delta, taskId: curr.task_id, nodeId: curr.node_id }); // Log delta
    lastEventByNode.set(key, curr); // Update last event for this node
    const statusForTemporal = curr.state; // Assuming 'state' is the primary status for Temporal
    if (!['DONE', 'FAILED'].includes(statusForTemporal)) {
        logger.debug(logCtx({ task_id: curr.task_id, status: statusForTemporal }), 'Skipping Temporal signal for non-terminal status based on original logic');
        return;
    }
    if (!USE_DAG_RUNNER) {
        logger.debug(logCtx({ task_id: curr.task_id, status: statusForTemporal }), 'â­ï¸ DAG_RUNNER=false â€” skipping event');
        return;
    }
    const wfId = `rail-event-dag-${curr.task_id}-v1`;
    logger.info(logCtx({ wfId, node_id: curr.node_id, status: statusForTemporal }), 'ðŸ“¤ Preparing to signal Temporal workflowâ€¦');
    // Lazy-init Temporal client
    if (!temporalClient)
        temporalClient = await getTemporalClient();
    await temporalClient.signalWithStart('main', {
        args: [{ taskId: curr.task_id }],
        workflowId: wfId,
        taskQueue: 'dag-runner',
        signal: 'nodeDone',
        signalArgs: [curr],
        workflowIdReusePolicy: WorkflowIdReusePolicy.ALLOW_DUPLICATE_FAILED_ONLY,
    });
    notificationsProcessed.inc({ status: statusForTemporal, instance_id: INSTANCE_ID });
    logger.info(logCtx({ wfId }), 'âœ… Workflow signaled successfully');
}
// -----------------------------------------------------------------------------
async function shutdownGracefully(reason) {
    logger.info(logCtx({ reason }), 'ðŸ›‘ Graceful shutdown requested');
    await new Promise(resolve => closeWebSocketServer(resolve)); // Close WebSocket server
    try {
        await closeTemporalClient();
    }
    catch { }
    try {
        await closePool();
    }
    catch { }
    if (activeListenerClient) {
        try {
            activeListenerClient.release();
        }
        catch { }
    }
    logger.info(logCtx({
        metrics: {
            processed: notificationsProcessed.get(),
            errors: listenerErrors.get(),
        }
    }), 'ðŸ“Š Shutdown complete with final metrics');
}
process.on('SIGINT', () => shutdownGracefully('SIGINT').then(() => process.exit(0)));
process.on('SIGTERM', () => shutdownGracefully('SIGTERM').then(() => process.exit(0)));
// -----------------------------------------------------------------------------
import pRetry from 'p-retry';
(async () => {
    logger.info(logCtx(), 'ðŸš€ Starting rail-events-listener bootstrapâ€¦');
    logger.info(logCtx({ USE_DAG_RUNNER }), `ðŸš¦ DAG_RUNNER = ${USE_DAG_RUNNER}`);
    logger.info(logCtx({ channel: CHANNEL }), `ðŸ“¡ Subscribing to PG channel: ${CHANNEL}`);
    try {
        await pRetry(bootListener, { retries: 5, minTimeout: 1_000, factor: 2 });
        logger.info(logCtx(), 'âœ… PostgreSQL listener booted');
        temporalClient = await getTemporalClient();
        logger.info(logCtx(), 'âœ… Temporal client ready');
        initializeWebSocketServer(logger); // Initialize WebSocket server with logger
        logger.info(logCtx(), 'ðŸŽ‰ Application started successfully and is listening for events.');
    }
    catch (err) {
        logger.fatal(logCtx({ err }), 'ðŸ’¥ Failed to start listener');
        await shutdownGracefully('startup failure');
        process.exit(1);
    }
})();
