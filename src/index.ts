import 'dotenv/config'; // Ensure env vars are loaded first //
import type { Notification, PoolClient } from 'pg';
import retry from 'p-retry';
import { collectDefaultMetrics, Counter } from 'prom-client';
import { getTemporalClient, closeTemporalClient } from './temporalClient.js';
import type { WorkflowClient } from '@temporalio/client';
import { WorkflowIdReusePolicy } from '@temporalio/common';
import {
  pool,
  query,
  closePool,
  STATEMENT_TIMEOUT_MS,
  IDLE_TX_TIMEOUT_MS,
} from './pg.js';

// ‚îÄ‚îÄ NATS setup (new) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
import {
  connect as natsConnect,
  type NatsConnection,
  StringCodec,
} from 'nats';

let natsConn: NatsConnection | null = null;
const sc = StringCodec();

async function getNats(): Promise<NatsConnection> {
  if (!natsConn) {
    natsConn = await natsConnect({
      servers: process.env.NATS_URL || 'nats://nats-scalable:4222',
    });
    console.log('rail-events-listener ‚Üí connected to NATS');
  }
  return natsConn;
}
// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

import { RailEvent, toDelta, BroadcastDelta } from './utils/delta.js';
import { initializeWebSocketServer, broadcast, closeWebSocketServer } from './websocketServer.js';

// -----------------------------------------------------------------------------
// Lightweight console-based logger (swap for pino in prod if desired)
export const logger = {
  info : (...a: any[]) => console.log(...a),
  warn : (...a: any[]) => console.warn(...a),
  error: (...a: any[]) => console.error(...a),
  debug: (...a: any[]) => console.debug(...a),
  trace: (...a: any[]) => console.trace(...a),
  fatal: (...a: any[]) => console.error(...a),
};

// -----------------------------------------------------------------------------
collectDefaultMetrics({ prefix: 'rail_events_listener_' });

const lastEventByNode = new Map<string, RailEvent>(); // key = taskId:nodeId

const CHANNEL        = process.env.PG_CHANNEL || 'rail_events';
const USE_DAG_RUNNER = process.env.DAG_RUNNER === 'true';
const INSTANCE_ID    = process.env.HOSTNAME || 'unknown';

const listenerErrors = new Counter({
  name: 'busywork_listener_errors_total',
  help: 'Unhandled errors in rail-events-listener',
  labelNames: ['instance_id'],
});

const notificationsProcessed = new Counter({
  name: 'rail_events_listener_notifications_processed_total',
  help: 'Total notifications processed',
  labelNames: ['status', 'instance_id'],
});

const logCtx = (extra: Record<string, any> = {}) => ({ instance_id: INSTANCE_ID, ...extra });

let temporalClient: WorkflowClient | undefined;
let activeListenerClient: PoolClient | undefined; // track for graceful shutdown

// -----------------------------------------------------------------------------
/** Boot a dedicated, long-lived LISTEN socket (retries inside p-retry). */
export async function bootListener(): Promise<void> {
  logger.info('Attempting to connect to PostgreSQL for LISTEN‚Ä¶');

  if (activeListenerClient) {
    try { activeListenerClient.release(); } catch {}
    activeListenerClient = undefined;
  }

  const client = await pool.connect();
  activeListenerClient = client;

  logger.info(
    logCtx({
      statement_timeout: STATEMENT_TIMEOUT_MS,
      idle_tx_timeout: IDLE_TX_TIMEOUT_MS,
    }),
    '‚úÖ Connected to PG for LISTEN',
  );

  await client.query(`SET statement_timeout TO 0; SET idle_in_transaction_session_timeout TO 0; SET client_min_messages TO WARNING;`);
  logger.debug('Session timeouts set to 0 for LISTEN socket');

  client.on('error', (err: Error) => {
    listenerErrors.inc({ instance_id: INSTANCE_ID });
    logger.error(logCtx({ err }), 'üí• PostgreSQL LISTEN client error ‚Äî reconnecting');
    try { client.release(err); } catch {}
    activeListenerClient = undefined;
  });

  client.on('notification', (msg: Notification) =>
    handleNotification(msg).catch((err) => {
      logger.error(logCtx({ err, payload: msg.payload }), 'üí• Error in handleNotification');
      listenerErrors.inc({ instance_id: INSTANCE_ID });
    }),
  );

  await client.query(`LISTEN ${CHANNEL}`);
  logger.info(logCtx({ channel: CHANNEL }), 'üîî LISTENING for events');

  /* ---------- 30-second SQL heartbeat ---------- */
  const heartbeat = setInterval(async () => {
    try {
      await query('SELECT 1');   // ‚úÖ grabs a fresh pool connection
      logger.info(logCtx(), '‚ù§Ô∏è listener heartbeat OK');
    } catch (err: any) {
      logger.warn(logCtx({ err }), 'üíî heartbeat failed ‚Äì connection likely lost');
    }
  }, 30_000);

  /* clear the interval when this client ends */
  client.once('end', () => clearInterval(heartbeat));
}

// -----------------------------------------------------------------------------
/** Parse and forward one NOTIFY payload. */
async function handleNotification(msg: Notification): Promise<void> {
  if (msg.channel !== CHANNEL || !msg.payload) return;

  let curr: RailEvent;
  try {
    const parsedPayload = JSON.parse(msg.payload);
    // Basic validation for RailEvent structure
    if (typeof parsedPayload !== 'object' || parsedPayload === null || 
        !parsedPayload.task_id || !parsedPayload.node_id || !parsedPayload.state) {
      logger.warn(logCtx({ payload: msg.payload }), 'Received payload does not conform to RailEvent structure');
      return;
    }
    curr = parsedPayload as RailEvent;
  } catch (e) {
    logger.error(logCtx({ err: e, payload: msg.payload }), 'Failed to parse notification payload');
    return;
  }

  const key = `${curr.task_id}:${curr.node_id}`;
  const prev = lastEventByNode.get(key) ?? null;
  let snapshotVersion: number = -1; // Default/error value

  try {
    const { rows } = await query('SELECT txid_current() AS v');
    if (rows && rows.length > 0 && rows[0].v !== null && rows[0].v !== undefined) {
      const parsedVersion = Number(rows[0].v);
      if (!isNaN(parsedVersion)) {
        snapshotVersion = parsedVersion;
        logger.info(logCtx({ taskId: curr.task_id, nodeId: curr.node_id, snapshotVersion }), 'Retrieved snapshotVersion for delta');
      } else {
        logger.warn(logCtx({ taskId: curr.task_id, nodeId: curr.node_id, rawValue: rows[0].v }), 'Failed to convert txid_current to Number for snapshotVersion');
      }
    } else {
      logger.warn(logCtx({ taskId: curr.task_id, nodeId: curr.node_id, rows }), 'Failed to retrieve txid_current or rows were empty/undefined for snapshotVersion');
    }
  } catch (err: any) {
    logger.error(logCtx({ err: { message: err.message, stack: err.stack }, taskId: curr.task_id, nodeId: curr.node_id }), 'üí• Error fetching txid_current for snapshot version');
    // snapshotVersion remains -1, indicating an issue. The frontend should handle this gracefully.
  }

  const delta: BroadcastDelta = toDelta(curr!, prev, snapshotVersion);

  broadcast(delta); // Call the imported broadcast function

/* ‚îÄ‚îÄ NEW: publish ‚Äúnode done‚Äù over NATS for side-cars ‚îÄ‚îÄ */
if (curr.state === 'DONE') {
  try {
    const nc = await getNats();
    await nc.publish(
      `busywork.node.done.${curr.node_id}`,      // subject
      sc.encode(JSON.stringify({
        taskId: curr.task_id,
        nodeId: curr.node_id,
      })),
    );
    logger.debug(logCtx({ node: curr.node_id }), 'üì§ NATS busywork.node.done published');
  } catch (err) {
    logger.error(logCtx({ err }), 'üí• NATS publish failed (non-fatal)');
  }
}
  logger.info({ deltaPayload: true, delta, taskId: curr.task_id, nodeId: curr.node_id }); // Log delta

  lastEventByNode.set(key, curr); // Update last event for this node

  const statusForTemporal = curr.state; // Assuming 'state' is the primary status for Temporal
  if (!['DONE', 'FAILED'].includes(statusForTemporal)) {
    logger.debug(logCtx({ task_id: curr.task_id, status: statusForTemporal }), 'Skipping Temporal signal for non-terminal status based on original logic');
    return;
  }

  if (!USE_DAG_RUNNER) {
    logger.debug(logCtx({ task_id: curr.task_id, status: statusForTemporal }), '‚è≠Ô∏è DAG_RUNNER=false ‚Äî skipping event');
    return;
  }

  const wfId = `rail-event-dag-${curr.task_id}-v1`;
  logger.info(logCtx({ wfId, node_id: curr.node_id, status: statusForTemporal }), 'üì§ Preparing to signal Temporal workflow‚Ä¶');

  // Lazy-init Temporal client
  if (!temporalClient) temporalClient = await getTemporalClient();

  await temporalClient.signalWithStart('main', {
    args: [{ taskId: curr.task_id }],
    workflowId: wfId,
    taskQueue: 'dag-runner',
    signal: 'nodeDone',
    signalArgs: [curr],
    workflowIdReusePolicy: WorkflowIdReusePolicy.ALLOW_DUPLICATE_FAILED_ONLY,
  });

  notificationsProcessed.inc({ status: statusForTemporal, instance_id: INSTANCE_ID });
  logger.info(logCtx({ wfId }), '‚úÖ Workflow signaled successfully');
}

// -----------------------------------------------------------------------------
async function shutdownGracefully(reason?: string) {
  logger.info(logCtx({ reason }), 'üõë Graceful shutdown requested');

  await new Promise<void>(resolve => closeWebSocketServer(resolve)); // Close WebSocket server
  try { await closeTemporalClient(); } catch {} 
  try { await closePool(); } catch {} 
  if (activeListenerClient) {
    try { activeListenerClient.release(); } catch {}
  }

  logger.info(logCtx({
    metrics: {
      processed: notificationsProcessed.get(),
      errors: listenerErrors.get(),
    }
  }), 'üìä Shutdown complete with final metrics');
}

process.on('SIGINT', () => shutdownGracefully('SIGINT').then(() => process.exit(0)));
process.on('SIGTERM', () => shutdownGracefully('SIGTERM').then(() => process.exit(0)));

// -----------------------------------------------------------------------------
import pRetry from 'p-retry';

(async () => {
  logger.info(logCtx(), 'üöÄ Starting rail-events-listener bootstrap‚Ä¶');
  logger.info(logCtx({ USE_DAG_RUNNER }), `üö¶ DAG_RUNNER = ${USE_DAG_RUNNER}`);
  logger.info(logCtx({ channel: CHANNEL }), `üì° Subscribing to PG channel: ${CHANNEL}`);

  try {
    await pRetry(bootListener, { retries: 5, minTimeout: 1_000, factor: 2 });
    logger.info(logCtx(), '‚úÖ PostgreSQL listener booted');
    temporalClient = await getTemporalClient();
    logger.info(logCtx(), '‚úÖ Temporal client ready');
    initializeWebSocketServer(logger); // Initialize WebSocket server with logger
    logger.info(logCtx(), 'üéâ Application started successfully and is listening for events.');
  } catch (err) {
    logger.fatal(logCtx({ err }), 'üí• Failed to start listener');
    await shutdownGracefully('startup failure');
    process.exit(1);
  }
})();
